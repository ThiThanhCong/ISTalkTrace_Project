# Enhance Speech Extraction And Speaker Identification

This project explores a hybrid approach for speaker identification by integrating feature extraction methods (MFCC, Wavelet, XVector, DVector) with classical and quantum machine learning models such as HMM, RNN, and Quantum Convolutional Neural Networks (QCNN).

## üìå Overview

In the era of virtual communication, the demand for intelligent audio analysis is rapidly growing. This work focuses on improving **speech extraction** and **speaker identification** through machine learning and quantum deep learning techniques.

Our best-performing model ‚Äî a hybrid **QCNN + HMM + DVector** architecture ‚Äî achieved **97% accuracy** and **95% F1-score** across 3-fold cross-validation.

## üß† Techniques Used

- Feature Extraction:
  - Mel-Frequency Cepstral Coefficients (MFCC)
  - Wavelet Transform (DWT)
  - X-Vector and D-Vector embeddings
- Models:
  - Hidden Markov Models (HMM)
  - Recurrent Neural Networks (RNN)
  - Quantum Convolutional Neural Networks (QCNN)
- Hybrid: QCNN combined with HMM for enhanced temporal modeling

## üìä Dataset

| Statistic                     | Value           |
|------------------------------|-----------------|
| Total number of speakers     | 83              |
| Total number of dialogues    | 10,430          |
| Number of speaker changes    | 751             |
| Total number of audio files  | 85              |
| Total duration               | 17.93 hours     |
| Average dialogue length      | 6.19 seconds    |
| Std. deviation of length     | 11.96 seconds   |

## üß™ Experimental Results

> **Table: Accuracy, Precision, Recall, and F1-Score Across 3 Folds**

| **Metric / Fold**    | HMM-MFCC | HMM-XVec | HMM-Wavelet | HMM-DVec | RNN-MFCC | RNN-XVec | RNN-Wavelet | RNN-DVec | QCNN-MFCC | QCNN-Wavelet | QCNN-XVec | QCNN-DVec | QCNN-HMM-MFCC | QCNN-HMM-Wavelet | QCNN-HMM-XVec | **QCNN-HMM-DVec** |
|----------------------|----------|----------|-------------|----------|-----------|-----------|--------------|-----------|-------------|----------------|------------|-------------|------------------|--------------------|----------------|----------------------|
| **Acc Fold 1**       | 0.49     | 0.66     | 0.15        | 0.36     | 0.78      | 0.69      | 0.39         | 0.86      | 0.42        | 0.16           | 0.11       | 0.44        | 0.83             | 0.32               | 0.95           | **0.97**             |
| **Acc Fold 2**       | 0.55     | 0.71     | 0.18        | 0.36     | 0.79      | 0.70      | 0.39         | 0.86      | 0.42        | 0.21           | 0.11       | 0.49        | 0.82             | 0.33               | 0.95           | **0.97**             |
| **Acc Fold 3**       | 0.48     | 0.67     | 0.17        | 0.35     | 0.78      | 0.75      | 0.39         | 0.86      | 0.56        | 0.18           | 0.11       | 0.48        | 0.83             | 0.34               | 0.95           | **0.97**             |
| **Prec Fold 1**      | 0.74     | 0.67     | 0.23        | 0.04     | 0.59      | 0.27      | 0.15         | 0.80      | 0.06        | 0.04           | 0.00       | 0.07        | 0.89             | 0.26               | 0.96           | **0.97**             |
| **Prec Fold 2**      | 0.74     | 0.74     | 0.27        | 0.04     | 0.70      | 0.34      | 0.17         | 0.80      | 0.06        | 0.07           | 0.00       | 0.07        | 0.88             | 0.26               | 0.96           | **0.97**             |
| **Prec Fold 3**      | 0.76     | 0.66     | 0.22        | 0.04     | 0.63      | 0.39      | 0.17         | 0.80      | 0.36        | 0.04           | 0.00       | 0.08        | 0.88             | 0.27               | 0.97           | **0.98**             |
| **Recall Fold 1**    | 0.69     | 0.59     | 0.12        | 0.10     | 0.53      | 0.28      | 0.14         | 0.74      | 0.09        | 0.05           | 0.01       | 0.10        | 0.87             | 0.19               | 0.93           | **0.95**             |
| **Recall Fold 2**    | 0.73     | 0.62     | 0.15        | 0.10     | 0.58      | 0.32      | 0.15         | 0.73      | 0.07        | 0.06           | 0.01       | 0.13        | 0.85             | 0.19               | 0.90           | **0.92**             |
| **Recall Fold 3**    | 0.71     | 0.56     | 0.12        | 0.10     | 0.56      | 0.39      | 0.16         | 0.74      | 0.31        | 0.04           | 0.01       | 0.13        | 0.86             | 0.21               | 0.92           | **0.94**             |
| **F1 Fold 1**        | 0.64     | 0.59     | 0.11        | 0.05     | 0.54      | 0.25      | 0.13         | 0.75      | 0.07        | 0.03           | 0.00       | 0.07        | 0.87             | 0.18               | 0.94           | **0.96**             |
| **F1 Fold 2**        | 0.66     | 0.63     | 0.14        | 0.05     | 0.59      | 0.30      | 0.14         | 0.74      | 0.05        | 0.04           | 0.00       | 0.08        | 0.85             | 0.17               | 0.92           | **0.94**             |
| **F1 Fold 3**        | 0.66     | 0.57     | 0.13        | 0.05     | 0.57      | 0.37      | 0.15         | 0.75      | 0.30        | 0.03           | 0.00       | 0.09        | 0.86             | 0.19               | 0.94           | **0.95**             |

## üîç Key Findings

- **DVector** features combined with **QCNN + HMM** yielded the best performance.
- **Wavelet + HMM** was the weakest performer.
- **RNN-DVec** also showed strong results but was outperformed by the hybrid quantum model.

## üõ† Tools & Frameworks

- Python
- [SpeechBrain](https://speechbrain.readthedocs.io/)
- Pennylane (Quantum ML)
- PyTorch
- Scikit-learn

## üìà Future Work

- Expand to noisy environments
- Add multilingual and emotion-aware capabilities
- Real-time deployment for smart assistants or security systems

## ü§ù Acknowledgments

This research was supported by the VNUHCM‚ÄìUniversity of Information Technology‚Äôs Scientific Research Support Fund.

---

## üìÑ Citation

If you use this work, please cite our paper:

> Cao Ho√†i Sang, Thi Th√†nh C√¥ng, Nguy·ªÖn Minh Nh·ª±t, Nguy·ªÖn ƒê√¨nh Thu√¢n. *Enhancing Speech Extraction And Speaker Recognition Through Machine Learning And Deep Learning Integration*. UIT, 2024.

---
